
import pandas as pd
import numpy as np
import random
import streamlit as st
from streamlit.logger import get_logger
from tqdm import tqdm
import numpy as np
import transformers
transformers.logging.set_verbosity_error()
from transformers import BertTokenizer, BertModel, BertConfig
from transformers import BertModel, BertConfig
import os
import torch
from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler
from torch.utils.data import Dataset


LOGGER = get_logger(__name__)
def number_to_letter(number):
    # åˆ›å»ºä¸€ä¸ªå­—å…¸ï¼Œå°†æ•°å­—æ˜ å°„åˆ°å¯¹åº”çš„å­—æ¯
    mapping = {0: 'A', 1: 'B', 2: 'C', 3: 'D'}
    # é€šè¿‡å­—å…¸è·å–å¯¹åº”çš„å­—æ¯
    return mapping.get(number, "Invalid number")  # å¦‚æœæ•°å­—ä¸åœ¨0åˆ°3ä¹‹é—´ï¼Œè¿”å›é”™è¯¯ä¿¡æ¯

def seed_everything(seed):
    random.seed(seed)
    os.environ['PYTHONHASHSEED'] = str(seed)
    np.random.seed(seed)
    torch.manual_seed(seed)
    torch.cuda.manual_seed(seed)
    torch.cuda.manual_seed_all(seed)
    torch.backends.cudnn.deterministic = True
    torch.backends.cudnn.benchmark = False

class MyDataset(Dataset):
    def __init__(self, dataframe):
        # å¦‚æœä¼ è¿›æ¥çš„dataframeå…¶å®æ˜¯å•ä¸ªæ ·æœ¬ï¼Œå°†å…¶è½¬åŒ–ä¸ºDataFrame
        self.df = dataframe if isinstance(dataframe, pd.DataFrame) else pd.DataFrame([dataframe])


    def __len__(self):
        return len(self.df)

    def __getitem__(self, idx):  # å°†ä¸€æ¡æ•°æ®ä»(æ–‡ç« ,é—®é¢˜,4ä¸ªé€‰é¡¹)è½¬æˆ(æ–‡ç« ,é—®é¢˜,é€‰é¡¹1)ã€(æ–‡ç« ,é—®é¢˜,é€‰é¡¹2)...
#         label = self.df.label.values[idx]
        label = self.df.iloc[idx].label  # ä½¿ç”¨ilocæ¥å…¼å®¹å•ä¸ªæ ·æœ¬çš„æƒ…å†µ
        question = self.df.Question.values[idx]
        content = self.df.Content.values[idx]
        choice = self.df.Choices.values[idx][2:-2].split('\', \'')
        if len(choice) < 4:  # å¦‚æœé€‰é¡¹ä¸æ»¡å››ä¸ªï¼Œå°±è¡¥â€œä¸çŸ¥é“â€
            for i in range(4 - len(choice)):
                choice.append('Dï¼ä¸çŸ¥é“')

        content = [content for i in range(len(choice))]
        pair = [question + ' ' + i[2:] for i in choice]

        return content, pair, label

def run():
    st.set_page_config(
        page_title="Hello",
        page_icon="ğŸ‘‹",
    )

    st.write("# Welcome here! ğŸ‘‹")

    st.sidebar.success("Select a demo above.")

    test_df = pd.read_csv('/workspaces/gra002/test.csv')
    # è·å–DataFrameçš„è¡Œæ•°
    num_rows = len(test_df)

    if st.button('ç»™æˆ‘ä¸€ä¸ªé—®é¢˜'):
        st.session_state.index = random.randint(0, num_rows - 1)
        test_df = pd.read_csv('/workspaces/gra002/test.csv')
        test_df['label'] = 0

        CFG = {  # è®­ç»ƒçš„å‚æ•°é…ç½®
            'fold_num': 5,  # äº”æŠ˜äº¤å‰éªŒè¯
            'seed': 42,
            'model': 'hfl/chinese-macbert-large',  # é¢„è®­ç»ƒæ¨¡å‹
            'max_len': 256,  # æ–‡æœ¬æˆªæ–­çš„æœ€å¤§é•¿åº¦
            # 'epochs': 12,
            'epochs': 10,
            'train_bs': 4,  # batch_sizeï¼Œå¯æ ¹æ®è‡ªå·±çš„æ˜¾å­˜è°ƒæ•´
            'valid_bs': 4,
            'lr': 2e-5,  # å­¦ä¹ ç‡
            'lrSelf': 1e-4,  # å­¦ä¹ ç‡
            'num_workers': 8,
            'accum_iter': 8,  # æ¢¯åº¦ç´¯ç§¯ï¼Œç›¸å½“äºå°†batch_size*2
            'weight_decay': 1e-4,  # æƒé‡è¡°å‡ï¼Œé˜²æ­¢è¿‡æ‹Ÿåˆ
            'device': 0,
            'adv_lr': 0.01,
            'adv_norm_type': 'l2',
            'adv_init_mag': 0.03,
            'adv_max_norm': 1.0,
            'ip': 2,
            'gpuNum': 1
        }

        # å‡è®¾ä½ çŸ¥é“ä½ æƒ³è¦åŠ è½½æ¨¡å‹çš„ç¡®åˆ‡ç±»å‹å’Œåç§°
        model_name = 'hfl/chinese-macbert-large'

        # é¦–å…ˆä»é¢„è®­ç»ƒæ¨¡å‹ååŠ è½½é…ç½®
        config = BertConfig.from_pretrained(model_name)

        # é€šè¿‡é…ç½®å®ä¾‹åŒ–æ¨¡å‹
        model = BertModel(config)

        # ç¡®ä¿æ¨¡å‹å¤„äºè¯„ä¼°æ¨¡å¼
        model.eval()

        # ç°åœ¨æ¨¡å‹å·²ç»åŠ è½½å¹¶å‡†å¤‡å¥½è¿›è¡Œé¢„æµ‹æˆ–å…¶ä»–æ“ä½œ
        tokenizer = BertTokenizer.from_pretrained(CFG['model'])  # åŠ è½½bertçš„åˆ†è¯å™¨
        def collate_fn(data):  # å°†æ–‡ç« é—®é¢˜é€‰é¡¹æ‹¼åœ¨ä¸€èµ·åï¼Œå¾—åˆ°åˆ†è¯åçš„æ•°å­—idï¼Œè¾“å‡ºçš„sizeæ˜¯(batch, n_choices, max_len)
            input_ids, attention_mask, token_type_ids = [], [], []
            for x in data:
                text = tokenizer(x[1], text_pair=x[0], padding='max_length', truncation=True, max_length=CFG['max_len'],
                                return_tensors='pt')
                input_ids.append(text['input_ids'].tolist())
                attention_mask.append(text['attention_mask'].tolist())
                token_type_ids.append(text['token_type_ids'].tolist())
            input_ids = torch.tensor(input_ids)
            attention_mask = torch.tensor(attention_mask)
            token_type_ids = torch.tensor(token_type_ids)
            label = torch.tensor([x[-1] for x in data])
            return input_ids, attention_mask, token_type_ids, label

        test_set = test_df.iloc[[st.session_state.index]]  # æ³¨æ„åŒæ‹¬å·ï¼Œè¿™æ ·è¿”å›çš„æ˜¯DataFrameè€Œä¸æ˜¯Series

        test_set = MyDataset(test_set)
        test_loader = DataLoader(test_set, batch_size=1, collate_fn=collate_fn, shuffle=False,
                                num_workers=1)

        device = torch.device("cuda:0" if torch.cuda.is_available() else "cpu")
        model.to(device)
        y_pred = []
        predictions = []

        with torch.no_grad():
            tk = tqdm(test_loader, total=len(test_loader), position=0, leave=True)
            for idx, (input_ids, attention_mask, token_type_ids, y) in enumerate(tk):
                input_ids, attention_mask, token_type_ids, y = input_ids.to(device), attention_mask.to(
                    device), token_type_ids.to(device), y.to(device).long()
            
                input_ids = input_ids.squeeze(0)
                attention_mask = attention_mask.squeeze(0)
                token_type_ids = token_type_ids.squeeze(0)            
                
                output = model(input_ids, attention_mask, token_type_ids)[0].cpu ().numpy()
                token_scores = np.max(output, axis=2)

                option_scores = np.mean(token_scores, axis=1)

                predicted_option = np.argmax(option_scores)
                st.session_state.pre=predicted_option
        # print(option_scores)

        prediction=number_to_letter(predicted_option)
        print(prediction)    
        
    st.write(test_df.iloc[st.session_state.index])

    genre = st.radio(
        "ä½ çš„ç­”æ¡ˆæ˜¯ï¼š",
        ["A ::smiling_face_with_3_hearts:", "B ::thermometer:", "C :blush:","D ::sun_with_face:"],
        # captions = ["Laugh out loud.", "Get the popcorn.", "Never stop learning."]
        index=None,)


    if(st.session_state.pre==0):
        if genre == 'A ::smiling_face_with_3_hearts:':
            st.balloons()
            st.write('You selected right!')
        else:
            st.write("You  select wrong!.")       

    elif(st.session_state.pre==1):
        if genre == 'B ::thermometer:':
            st.balloons()
            st.write('You selected right!')
        else:
            st.write("You  select wrong!.")  

    elif(st.session_state.pre==2):
        if genre == 'C :blush:':
            st.balloons()
            st.write('You selected right!')
        else:
            st.write("You  select wrong!.")  

    elif(st.session_state.pre==3):
        if genre == 'D ::sun_with_face:':
            st.balloons()
            st.write('You selected right!')
        else:
            st.write("You  select wrong!.")  


    st.markdown(
        """
        æœ¬é¡¹ç›®çš„æ•°æ®æ¥è‡ªå°å­¦/ä¸­é«˜è€ƒè¯­æ–‡é˜…è¯»ç†è§£é¢˜åº“ã€‚ç›¸è¾ƒäºè‹±æ–‡ï¼Œä¸­æ–‡é˜…è¯»ç†è§£æœ‰ç€æ›´å¤šçš„æ­§ä¹‰æ€§å’Œå¤šä¹‰æ€§ï¼Œç„¶è€Œç’€ç’¨çš„ä¸­åæ–‡æ˜å¾—ä»¥ç»µå»¶æ•°åƒå¹´ï¼Œç¦»ä¸å¼€æ¯ä¸€ä¸ªæ—¶ä»£é‡ŒåŠªåŠ›é’»ç ”ã€åšå®ˆä¼ æ‰¿çš„äººï¼Œè¿™ä¹Ÿæ­£æ˜¯æœ¬é¡¹ç›®çš„é­…åŠ›ä¸æŒ‘æˆ˜ï¼Œè®©æœºå™¨è¯»æ‡‚æ–‡å­—ï¼Œè®©æœºå™¨å­¦ä¹ æ–‡æ˜ã€‚

        **â˜ éšæœºç”Ÿæˆä¸€é“é¢˜ç›®æ¥æµ‹è¯•ä¸€ä¸‹å§** 

    """
    )


if __name__ == "__main__":
    if "index" not in st.session_state:
        st.session_state.index = 0

    if "pre" not in st.session_state:
        st.session_state.pre = 0
    run()

